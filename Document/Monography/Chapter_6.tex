\begin{appendices}
\chapter{Z-score Standardization}\label{ap:zscore}
The function np.polyfit (), during the process of calculating the fourth-order polynomial fit, presents an over estimation on the coefficients due to the large difference of magnitude order between axes.
To deal with this difference, was applied a z-score standardization on the selected bins of wavelengths around the minimum reference point. 
This process helps to avoid the dominance of certain features over others due to differences in their scales~\cite{Boyd_2014}.

For the standardization was applied Equation~\eqref{eq:z score} on the selected bins for wavelength around the minimum reference point.
\begin{equation}
\lambda_{\text{scaled}}= \frac{\lambda_{\text{original}}-\mu(\lambda_{\text{original}})}{\sigma(\lambda_{\text{original}})}
\label{eq:z score}
\end{equation}
Where $\mu(\lambda_{\text{original}})$ refers to the mean and $\sigma(\lambda_{\text{original}})$ to the standard deviation of the wavelength range. 
In terms of calculating derivatives for the first and second signature of convection, the standarization on the variable required a re-scaled factor of conversion for obtain the original values.
Based on the definition for the standardization, the derivatives have to follow Equation~\eqref{eq:re scaled derivates}.

\begin{equation}
 \frac{d}{d \lambda_{\text{original}}} = \frac{1}{\sigma(\lambda_{\text{original}})} \frac{d}{d \lambda_{\text{scaled}}}
\label{eq:re scaled derivates}
\end{equation}

Taking the derivative of the expression~\eqref{eq:z score} a factor related to the standard deviation appears.
Therefore, the original values for derivatives evaluated in the observed wavelength are expressed in Equation~\eqref{eq:2 and 3 scaled derivate}

\begin{equation}
 \frac{d^2}{d \lambda_{\text{original}}^2} = \frac{1}{\sigma(\lambda_{\text{original}})^2} \frac{d^2}{d \lambda_{\text{scaled}}^2} \quad\quad \quad \frac{d^3}{d \lambda_{\text{original}}^3} = \frac{1}{\sigma(\lambda_{\text{original}})^3} \frac{d^3}{d \lambda_{\text{scaled}}^3}
\label{eq:2 and 3 scaled derivate}
\end{equation}

The treatment proposed solves the problem for the large difference of magnitude order between axes.

\chapter{The third derivate relation}\label{ap:third derivative}

The third derivate relation or called the line profile bisector slope was deducted by Professor Benjamin and showed below.

Defined the slope as equation~\eqref{eq:slope}, where the points $b,c,h$ are illustrated in the figure~\ref{fig:slope}

\begin{equation}
 CBS = \lim_{h\to 0} \frac{\frac{b+c}{2}-a}{h}
\label{eq:slope}
\end{equation}

Note that in a symmetrical line the bisector is vertical and the slope, according to this definition, is zero.
Now, the curve may be expanded around the point $a$ by Taylor series noticing that $a$ is chosen at the minimum, so $f'(a)=0$ and $f(c)-f(a)=h$,giving

\begin{equation}
 2h=(c-a)^2f''(a)+\frac{1}{3}(c-a)^3f'''(a)
\end{equation}

We may abbreviate $c-a=x>0$ and likewise $b-a=y<0$ obtaining

\begin{equation}
 2h=x^2f''(a)+\frac{1}{3}x^3f'''(a) \quad \quad 2h=y^2f''(a)+\frac{1}{3}y^3f'''(a)
\end{equation}

So, $x$ and $y$ are two equations roots. 
One of the possible roots for the cubic polynomial equation, the two that are needed whose that trend to 

\begin{equation}
 CBS = \lim_{h\to 0} \frac{x}{y} = -1
\end{equation}

If the polynomial equation is written in the standard form $ax^3+bx^2+cx+d=0$ the coefficients are
$a=\frac{f'''}{3}$, $b=f''$, $c=0$, $d=-2h$. A standard procedure is to change the variable to $x=t-\frac{b}{3a}=t-\frac{f''}{f'''}$
which produces the "depressed" equation.

\begin{equation}
 t^3+pt+q=0 \quad \rightarrow \quad p=-3\parens{\frac{f''}{f'''}}^2 \quad q = 2\frac{(f'')^3-3h(f''')^2}{(f''')^3}
\end{equation}

Where the equation have three solutions of the form:
\begin{equation}
 t_i = 2\parens{\frac{f''}{f'''}}\cos\parens{\frac{1}{3}\arccos\parens{\frac{3h(f''')^2}{(f'')^3} - 1} -\frac{2\pi i}{3}}
\end{equation}

When $h$ vanishes, there are two equal solutions and one differing. Let's abbreviate
\begin{equation}
\epsilon = \frac{h(f''')^2}{(f'')^3} <<1
\end{equation}

In the limit $h\to 0$ we have $\epsilon <<1$ which means $\arccos(3\epsilon -1)=\pi-\delta$ with $\delta$ an small angle.
So, $\delta=\sqrt{6\epsilon}$ and the solution is the next equation.

\begin{equation}
t_{\pm} = 2\frac{f''}{f'''}\parens{\frac{1}{2}\cos\parens{\frac{\sqrt{6\epsilon}}{3}} -/+ \frac{\sqrt{3}}{2}\sin\parens{\frac{\sqrt{6\epsilon}}{3}} }
\end{equation}

For the bisector slope appears the next condition.

\begin{equation}
x+y = t_+ + t_- - 2\parens{\frac{f''}{f'''}} = -\frac{2}{3}\parens{\frac{f''}{f'''}}\epsilon = -2h\frac{f''}{3(f''')^2}
\end{equation}

Whence, finally, the core bisector slope is defined by equation~\eqref{eq:CBS}

\begin{equation}
CBS =  -\frac{f''}{3(f''')^2}
\label{eq:CBS}
\end{equation}

In the code it was multiplied by the relation ($\frac{c}{\lambda}$) to see the behavior across line depth in the graphic.

\chapter{Visualizer for outliers}\label{ap:visualizer}

For the line selection process mentioned in Chapter 3, a visualizer was created using the Tkinter library to aid in identifying blend lines or those outside the spectrum. 

Two versions of the visualizer were developed, each utilizing different filters. The first filter displays the geometry of the line core and the line profile c-curved bisector. The second filter, which builds on the selected lines from the first, shows the three signatures of convection and the behavior of the selected line in each one. 

This visualizer significantly reduced the time spent reviewing lines. It also features a custom classification system, shown as color stars. These buttons don't make something on the Dataframe more than just a label for the user orientation. Also, allows the users to add lines to a DataFrame, specially for the lines which are gonna to be deleted or filtered due to bad reputation, and save images. The code for the visualizer can be seen on \href{https://github.com/ccuellarn/Final-Project}{GitHub}, along with a test example provided below.

The main code for this project is contained in the file Visualizer.ipynb, and a test example dataset is provided in test.xlsx. 
To facilitate analysis, two DataFrames were created: One for the spectrum with columns Wave and Flux, representing wavelength in Armstrongs and normalized flux, respectively, and another for the list of Fe I lines. 
The closer lines  function was used to select the closest minimums to the Fe I lines, along with their associated flux values and Fe I line wavelengths.

Beware, these Fe I line wavelengths serve as reference points for selecting bins around each line, rather than representing observed wavelengths. The function discards any lines with distances between minimums and Fe I lines exceeding $0.001\mathring{A}$. Furthermore, to ensure convexity, fourth-order polynomial fits with non-positive second-order coefficients were discarded. An approximation was used to discard lines that do not belong to the spectrum.

A computational form of a slope can be seen as the difference between the maximum and minimum point of the list of points. In terms of flux if it is seen the distance can't be more than a half of the absolute difference. This lets us discard pronounced slopes without affecting or filtering weaker lines.
Then use the function local points for selecting the bins of $0.1m\mathring{A}$ around the minimal point, each corresponding to one index on the closer lines dataframe. 

The function Fit Derivatives finds the fourth order polynomial fit and calculates the minimum point with the second derivative of the fit, that is the observed wavelength. This returns a Dataframe with the value of Fe I line associated, the polynomial fit, and the observed wavelength. In parallel, the line profile bisector is calculated using the midpoint method where equal points of flux are selected for comparison.

The first visualizer uses these calculated values, showing the line core and the fourth polynomial fit, in parallel with the line profile bisector of each one in terms of velocity.

We recommend eliminating the lines that follow one of the conditions presented. First, the line profile bisector doesn't show a C-curved bisector or it's too affected by the noise. Second, the polynomial fit and the line profile don't follow a common absorption line form. This can be interpreted as the position on other points to the fit. Third, the line core shows two minimums or a protuberance. These are blended lines. An example of this behavior is shown on figure ().

The objective of the first filter is to reduce the number of lines for analyzing the three signatures of convection.

The second part of the code calculates the three signatures of convection for the filtered lines. The second visualizer shows all the graphics including the line profile with the polynomial fit. In each graphic of derivatives the corresponding Fe I is resalted, this with the finally to select lines depending on his behavior.
 
\section{Test example}

In the file test example.ipynb run the line code.

\begin{lstlisting}
raw_data = read.csv(jsjsjsj)

\end{lstlisting}

Feel free to modify this line to read the file type. 
The idea is the Dataframe results have the columns Wave (cm), nFlux and Wave A. There's no need for the flux to be normalized, because nothing in the code uses the condition of normalized flux. 
Then run the list of calibration lines. 
In this case, we use the Nave list of Fe I lines. A test example list is displayed on the carpet Data.

\begin{lstlisting}
raw lambda =

\end{lstlisting}

Run the next two cells where the functions closer lines and local points are displayed.

\begin{lstlisting}
closer_lines_first_filter =
local_points_first_filter=

\end{lstlisting}

With this dataset, run the cell for the applied the first filter.

\begin{lstlisting}
Values_first_filter, Local_first_filter, Fit_first_filter, Bisector_first_filter = First_Filter()

\end{lstlisting}

On the cell code for the visualizer just comment the cell before running.

\begin{lstlisting}
app1= app(run, local_first_filter)

\end{lstlisting}

To extract the Dataframe with the lines to drop or for further analysis run the cell.
 Make sure that the visualizer is closed after running another cell code.

\begin{lstlisting}
Dataframe to drop =

\end{lstlisting}

The cell  saves the filtered lines and the suspect ones in two different xlsx files.

\begin{lstlisting}
Values.save()

\end{lstlisting}

With the new list of filtered lines, run the cell  to redefine the list of Fe I lines with only the filtered ones.

\begin{lstlisting}
raw lambda = 

\end{lstlisting}

Now, run again the code for closer lines and local points with the new list of Fe I lines. 
Then run the cell for applied the second filter and calculate the three signatures of convection

\begin{lstlisting}
Values_second filter = Second Filter()

\end{lstlisting}

As the same with the first filter, just comment the line to observe the second filter.

\begin{lstlisting}
app2= Second filter(run, local points, values)

\end{lstlisting}

The cell  helps to extract the lines to drop and remove it for the Dataframe.

\begin{lstlisting}
Values.save()

\end{lstlisting}

After the process, the resulting excel is the definitive list of Fe I lines.

\end{appendices}



